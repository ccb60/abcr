---
title: "Parsing ABC Tunes with `rly`"
output: html_notebook
---

# Introduction
In this notebook, I explore the R parsing engine `rly`.  `rly` is a port to R of 
a python package, `ply`. the name `ply` implies "python lex and yacc", where
"lex" and "yacc" are classic UNIX tools for building formal parsers. 

The challenge here is that because of the complex history of `rly`, `ply`, 
"lex" and "yacc", there are layers and layers of useage that are not clearly
explained in available documentation for `rly`, and few examples.  Instead,
we need to figure out `rly` indirectly, by understanding `ply`. 

This Notebook documents "lessons learned" while building up to a 
full-fledged parsing system for ABC files.

## The Structure of `rly`  
The package `rly`, as an R implementation of "lex" and "yacc", provides tools
for implementing both a "lexer" and a "parser". 

You construct a lexer by calling the function `rly::`lex()`.  You create a 
parser by calling the function `rly::yacc()`.

To parse an input string, you apply the lexer and the parser to the
input.

## R6 Classes and `rly`
THE package is built in R via the R6 object oriented system (see Chapter 14 of
Hadley Wickham's *Advanced R* for a primer on this flavor of object oriented
programming in R).

R6 provides a form of object oriented programming that is a lot like python's 
class-based object oriented programming style.  An R6 Class encapsulates both 
methods (functions) and attributes (data).

In R6, creating an R6 object occurs in two steps -- just like in python.
First, you have to create an R6 Generator, then you produce actual R6 objects as 
instances of the class using that generator.  This is exactly analogous to how
you generate an object of a specific class in python.  First you define the
Class, then you instantiate that class by calling the Class constructor.

R6 objects turn up a lot in `rly`.  The user designs lexers and parsers by
constructing R6 objects to pass to `lex()` and 'yacc()`.  The objects those two
functions produce are themselves R6 objects, and (at least by default), many of
the underlying data structures are R6 objects as well.

# Load libraries
I keep dependencies to a minimum here, so examples can be applicable in more
settings.  I make light use of the tidyverse for data manipulation, (`dplyr`) 
and little moree.

The only reason we use the `abcr` package is to access a couple of tune 
examples.  
```{r}
#library(tidyverse)
#library(dplyr)
#library(tibble)
library(abcr)
#library(stringr)
library(rly)
#library(data.tree)
```

# A Simple Tune Lexer
A Lexer accepts a stream of text input, and identifies discrete tokens. Each
token is a molecule of meaning that you may want to interpret further as you 
parse the text input.

This first lexer takes a string of ABC Notes, with or without white space, and 
converts it to a sequence of tokens, in order.  Not verty exciting.

Each token is defined either as a literal,  via a REGEX, or via a function.  The
choice of what to code each way has implications for precedence, but for
now, we only use REGEX expressions.

We start by producing a lexer that can handle a very reduced form of ABC:
a string of notes,

## Simple Data
```{r}
arpeggios <- "CEG2 CFA2 DGB2"
```

## The Lexer
ABC notes are basically letters indicating pitch names from A to G.  To code
the two octaves beginning with middle C, which correspond to melody lines in a
lot of folk music, Those letters can be capitalized (Octave 4) or not (octave
5).  Those bare pitch names can be decorated with other information, especially 
with one or more leading sharp or flat indicators, one or more trailing octave 
adjustment indicators, and a following number that indicates the note duration 
(usually in eighths).

In constructing the R6 object that will produce the parser, we define 
a list of tokens, a list of literals, and specially-named REGEX strings or 
functions, each of which begin with a "t-". The order of functions matters.
Strings caught in earlier REGEX don't get caught by later ones.  Only items
that "fall through" all prior REGEXes hit `t-error()`.
```{r}
TOKENS = c('ACCIDENTAL', 'BASENOTE', 'OCTAVE_ADJ', 'DURATION', 'WHITESPACE')
LITERALS = c()

SmallLexer <- R6::R6Class("Lexer",
  public = list(
    tokens = TOKENS,
    literals = LITERALS,
    t_ACCIDENTAL = '[\\^=_]',
    t_BASENOTE = "[a-gA-G]",
    t_OCTAVE_ADJ = "[\\',]+",
    
    t_DURATION = function(re='\\d+', t) {
         t$value <- strtoi(t$value)
         return(t)
    },
    t_WHITESPACE = "\\s+",
    
    # we Need a Function to Increment Line Numbers, to elp withe fixing errors
    t_newline = function(re='\\n+|(?:\\n\\r)+', t) {         
      t$lexer$lineno <- t$lexer$lineno + nchar(t$value)
      return(NULL)
    },
    
    # define an error function for unrecognized tokens or characters,
    # here we simply skip to teh next character and try again.
    t_error = function(t) {
      cat(sprintf("Illegal character '%s'", t$value[1]))
      t$lexer$skip(1)
      return(t)
    
    }
  )
)

smalllexer <- rly::lex(SmallLexer)
```


We use a parser4 by feeding it some input (with the `$input()` method) then 
pulling tokens out one at a time(with the `$token()` method).
```{r}
smalllexer$input(arpeggios)
while (!is.null(current_token <- smalllexer$token())) {
  print(current_token)
}
```

Each LexToken is itself an R6 object, with a print method that hides some 
details of the R6 implementation.  The visible contents are (in order):  
*  Token TYPE
*  TOKEN VALUE
*  Line number (always 1 if you don't manage the line count yourself.)
*  Position in the source text (NOT character count, but token count).

A full list of methods and attributes is accessible because R6 is built on top
of r environments.  We find methods `$clone()`, `$print()`, and `$toString()`.
```{r}
smalllexer$input(arpeggios)
(tok <- smalllexer$token())
ls(tok)
```
Attributes are accessible too.  The ones shown in the display, which are the 
ones most users may want to manipulate, are accessible via attributes `$type`, 
`value`, `lexpos`, and `lineno`. But there is no error checking....

```{r}
tok$lineno <- 7
tok$lexpos <- 17
tok$type = 'SLOPPY!'
tok
```
```{r}
tok$lexer
tok$parser
```

## What's in a Lexer?

We use a little introspection to understand the structure of a Lexer, created 
from a Lexer Generator, with the function 
`lex()`.

### Methods
According to the man pages for `rly::Lexer`, each lexer only has a few
public methods. These include:

input() - Store a new string in the lexer

token() - Get the next token

clone() - Clone the lexer (shallow clone by default)

We've seen how to use both `input()` and `token()` already.  `clone()` makes
a copy of the Lexer.  I'm not sure why you would want to do that in normal 
programming practice, since you can reuse a lexer fairly effortlessly.

There are actually a few more methods, but they are not intended for external
use.

### Attributes
The Man pages suggest only a couple of the attributes of a Lexer are intended 
for public use:

lineno:  Current line number

lexpos:  Current position in the input string

Numerous other attributes are used by the lexer internally to manage the
lexing process.

# A Simple Tune Parser.
Next, we build a simple parser to take the output from a lexer and turn in into
something more useful.  Our goal here is a data frame of notes with 
accidentals, pitch name, octave, and duration.

The general steps are similar: we have to define the structure of a parser with
a combination of tokens, literals, and parsing fnctions, defined by formal grammar.

The rules of the parser here take on a form that was inherited from
the original `yacc` program, and redefined in python's `ply`.

Each rule combines a grammar rule that expresses how to combine tokens,
with code (in R) that is run each time that particular rule is invoked
during parsing.

The rules are embodied in a function with names that start with 'p_'. Each
function must contain a parameter `doc`, with a  default string that defines 
the parsing rule. The function also takes a second argument, conventionally 
named `p`. The body of the function is the action to take when that rule is
invoked. (The name "doc" derives from the Python implementation, which located 
the parsing rules in the "docstring" associated with each function.)

The function parameter `p` represents a "YaccProduction" R6 object.
Documentation on the nature of this object is  sparse.
The class is a wrapper around the objects actually passed to each grammar rule.
Index lookup and assignment access the .value attribute of the underlying
object.  Subscripts step through the symbols in the grammar definition.

The primary responsibility of each function is to transform the values of P,
which are then passed on to the next function, and so on.  If the input string
is successfully parsed, the parser returns the final value of p -- presumably 
some sort of useful data structure in our case.

Each function can, in principal, alter external data structures, set flags, etc.

## A `note` Class
We want a consistent interface to some underlying data types here, most 
important is the concept of a NOTE, which consists of the combination 
of accidentals, a note name, an octave specification, and a duration.

We could construct a simple R6 class for this purpose, which is quite natural,
since we are working with R6 classes already, but R6 is not very much in keeping 
with R idioms.  

The alternative is to 'build' an S3 class. But S3 "class" is all about method
dispatch, so what we would need clarity on what methods would simplify 
coding the parser.

The main thing we would want for an S3 class would be constructor function, and
a print function that overrides the default print method for a list. (Hadley
also recommends a validator function for any S3 class).  We implement
`print.note()` indirectly, using `validate.note()` and `format.note()`.  That makes
it slightly easier to use (e.g.) `cat()`.

```{r}
new_note <- function(name, accidentals, octave, duration) {
  stopifnot(is.character(name) && length(name) == 1)     # Name is a single character
  stopifnot (grepl('[A-G]', name))
  
  stopifnot(is.numeric(accidentals) && accidentals%%1 == 0 && abs(accidentals <= 4))
  stopifnot(is.numeric(octave) && octave%%1 == 0 && abs(octave -4 <= 5))
  
  stopifnot (is.numeric(duration) && duration > 0  && 
               duration <= 64 )  # may not ALWAYS work, since depends on note length
  
  note <- structure(list(name = name,
                         accidentals = accidentals,
                         octave = octave,
                         duration = duration),
                    class = 'note')
}
```

Note that this data model carries accidental values with each note.  That means (so far)
it does not follow the convention of musical notation of implicitly adding sharps and 
flats for notes found in a well-defined key.

```{r}
validate_note <- function(note) {
  result <-  names(note) == c('name', 'accidentals', 'octave', 'duration')

  result <- result &&
      is.character(note$name) && length(note$name) == 1 &&     # Name is a single character
      grepl('[A-G]', note$name)                          # a letter from a to G, uppercase

  result <- result &&
      is.numeric(note$accidentals) && 
      note$accidentals%%1 == 0 && 
      abs(note$accidentals <= 4)
    
  result <- result && 
      is.numeric(note$octave) && 
      note$octave%%1 == 0 && 
      abs(note$octave - 4 <= 5)  # Restricted range of octaves -- is this adequate?
  
  result <- result && 
  is.numeric(note$duration) && 
    note$duration > 0  && 
    note$duration <= 64
  return(result)
  }

format.note <- function(note) {
  if(validate_note(note)) {
    s_or_f <- sign(note$accidental)
    if (s_or_f < 0) {
      acc_str <- paste(rep('b', abs(note$accidental)), collapse = '')
    } else if (s_or_f > 0) {
      acc_str <- paste(rep('#', abs(note$accidental)), collapse = '')
    } else{
      acc_str <- ''
    }
    return(paste0('Note: ', note$name, acc_str, '{', note$octave, '}', note$duration))
  } else {
    stop('Value is not a valid note object!')
  }
}

print.note <- function(note) {
  print(format(note))
}

```

```{r}
char = "B"
accidental = -1
octave = 4
duration  = 2

nt <- new_note(name = toupper(char), accidental = accidental, 
                          octave = octave, duration = duration)
#validate_note(nt)
nt
```

## Specifying the Parser
The Parser specification has a number of quirks that are not clearly laid out in
the documentation, the most important is how one accesses the object that is
being passed along the parsing chain.

Each parsing function takes two arguments, `doc`, and `p`. I believe the choice of 
the name `p` is arbitrary, and may be confusing at times.

The object `p` is an R6 object, a "YaccProduction" that acts something like a
list, except that positional access is not through traditional R subsetting
using `[` and `[[`, but through `$set()` and $get()` methods.

`$get(1)` and `$set(1,value)` get and set, respectively the first item in the 
related parsing rule : the single item on the left hand side. Ordinarily, this is the
RESULT of the parsing step, built as some sort of a function of the items
passed in in the RHS of the parsing rule.

`$length()` tells you how many items were in the parsing rule.  We used that
function a lot in this early code, but the  manual for 'ply', an ancestor to `rly` 
in Python, recommends against this approach.  Separating different length rules 
cleanly into different rules, rather than combining them with OR, tends to be 
more efficient.

```{r}
SmallParser <- R6::R6Class("Parser",
  public = list(
    tokens = TOKENS,  # defined above!
    literals = LITERALS,
    # Parsing rules
    p_note_seq = function(doc = 'note_seq : note note_seq
                                          | spaced_note note_seq
                                          | note
                                          | spaced_note', p) {
      if(p$length() == 2) {
        p$set(1, list(p$get(2)))
      } else {
        p$set(1, append(p$get(3), list(p$get(2)), after = 0))  # probably slow....
      }
      # for (item in p$get(1)) {
      #   cat('\n')
      #   cat(item[[1]])
      # }
    },
    
    
    p_spaced_note = function(doc = 'spaced_note : note WHITESPACE', p) {
      p$set(1, p$get(2))
    },
    
    p_note  = function(doc = 'note : fullpitch
                                   | fullpitch duration', p) {
      if(p$length() == 2) {
        p$set(1, p$get(2))
      } else {
        note <- p$get(2)
        note$duration <- p$get(3)
        p$set(1, note)
        
      }
    },
    
    p_duration = function(doc = 'duration : DURATION', p) {
      p$set(1, strtoi(p$get(2)))
    },
    
    p_fullpitch = function(doc = 'fullpitch : notename
                                            | notename OCTAVE_ADJ', p) {
      if(p$length()== 3) {
        note <- p$get(3)
        chars <- p$get(2)
        chars <- strsplit(chars, '')
        octave <- note$octave
        for (n in seq_along(chars)) {
          if (chars[n] == "'") {
            octave = octave + 1
          } else if (chars[n] == ',') {
            octave = octave - 1
          }
        }
        note$octave <- octave
        p$set(1, note)
      }
      p$set(1, p$get(2))   # is this needed?
      
    },
    
    p_notename =  function(doc = 'notename : basenote 
                                            | ACCIDENTAL basenote', p) {
      if(p$length() == 3) {
        print(p$get(2))
        note <- p$get(3)
        chars <- p$get(2)
        chars <- strsplit(chars, '')
        accidental <- note$accidental
        for (n in seq_along(chars)) {
          if (chars[n] == '^') {
            accidental = accidental + 1
          } else if (chars[n] == '_') {
            accidental = accidental - 1
          }
        }
        note$accidental <- accidental
        p$set(1, note)
      } else {
        p$set(1, p$get(2))   # is this needed?
      }
    },
    
    # we start with basenote, to create a new note data structure, which we modify
    # as we add other components to determine true_pitch and pitch duration.
    p_basenote    = function(doc = 'basenote : BASENOTE', p) {
      char <- p$get(2)
      if (char == toupper(char)) {
        octave <- 4
      } else {
        octave <- 5
      }
      # create our note data structure
      p$set(1, new_note(name = toupper(char), accidental = 0, 
                        octave = octave, duration = 1))
    },
    
    p_error = function(p) {
      if(is.null(p)) cat("Syntax error at EOF")
      else           cat(sprintf("Syntax error at '%s'", p$value))
    }
  )
)

smallparser <- yacc(SmallParser, debug = TRUE)

```

```{r}
smalllexer$input(arpeggios)
while (!is.null(tok <- smalllexer$token())) {
  print(tok)
}
```

```{r}
p <- smallparser$parse(arpeggios, smalllexer)
p
```

```{r}
arpeggios_2 <- "GBD2 GCE2 AD^F2"
```

```{r}
p <- smallparser$parse(arpeggios_2, smalllexer)
p
```



```{r}
smalllexer$input('B2c^2d4')
while (!is.null(tok <- smalllexer$token())) {
  print(tok)
}
```

```{r}
p <- smallparser$parse('B2c^2D4', smalllexer)
p
```

# Other R Parsing Engines
Google Searches turn up the following parsers in R.

Minimalist regex-based parsing engine -- not so useful for nested 
grammars.
Flexo https://github.com/coolbutuseless/flexo

rly package
https://cran.r-project.org/web/packages/rly/index.html
formal impelentation of lex and yacc in R.

dparser package
https://cran.r-project.org/web/packages/dparser/index.html

minilexer package
https://coolbutuseless.bitbucket.io/2018/03/26/parsing-data-part-1.-the-minilexer-package---a-simple-lexer-in-r/


# R Packages that simplify Tree Data Structires
https://cran.r-project.org/web/packages/data.tree/vignettes/data.tree.html



# A Formal Grammear 
Henrik Norbeck, in 1997 released a formal BNF grammar for ABC 1.6.  Although 
it is slightly out of date, and incomplete, it provides useful insight into
what is needed to parse a whole ABC file.
http://web.archive.org/web/20080309023424/http://www.norbeck.nu/abc/abcbnf.htm
